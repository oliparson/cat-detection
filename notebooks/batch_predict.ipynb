{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from google.cloud import storage\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import io\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import tensorflow as tf\n",
    "import os\n",
    "from PIL import Image\n",
    "import json\n",
    "import time\n",
    "import re\n",
    "import googleapiclient.discovery as discovery\n",
    "from googleapiclient import errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define bucket and blob prefix\n",
    "\n",
    "project = 'optimum-treat-262616'\n",
    "photo_bucket_name = 'catflap-photos-raw'\n",
    "model_bucket_name = 'cat-detection-models'\n",
    "prefix = '2020-06-01'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create input json file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up buckets\n",
    "\n",
    "client = storage.Client()\n",
    "photo_bucket = client.get_bucket(photo_bucket_name)\n",
    "model_bucket = client.get_bucket(model_bucket_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5822\n"
     ]
    }
   ],
   "source": [
    "# Get list of blob names\n",
    "\n",
    "blobs = photo_bucket.list_blobs(prefix=prefix)\n",
    "blob_list = [blob.name for blob in blobs]\n",
    "print(len(blob_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-06-07 15:11:49.912670 0\n",
      "2020-06-07 15:11:57.674853 100\n",
      "2020-06-07 15:12:04.841299 200\n",
      "2020-06-07 15:12:12.972489 300\n",
      "2020-06-07 15:12:23.971038 400\n",
      "2020-06-07 15:12:34.884835 500\n",
      "2020-06-07 15:12:46.433051 600\n",
      "2020-06-07 15:12:57.735909 700\n",
      "2020-06-07 15:13:09.199341 800\n",
      "2020-06-07 15:13:20.556126 900\n",
      "2020-06-07 15:13:31.906892 1000\n",
      "2020-06-07 15:13:42.954666 1100\n",
      "2020-06-07 15:13:54.119665 1200\n",
      "2020-06-07 15:14:05.650092 1300\n",
      "2020-06-07 15:14:16.753098 1400\n",
      "2020-06-07 15:14:27.982812 1500\n",
      "2020-06-07 15:14:38.684336 1600\n",
      "2020-06-07 15:14:49.863019 1700\n",
      "2020-06-07 15:15:00.798460 1800\n",
      "2020-06-07 15:15:12.271462 1900\n",
      "2020-06-07 15:15:22.810127 2000\n",
      "2020-06-07 15:15:34.062328 2100\n",
      "2020-06-07 15:15:44.920822 2200\n",
      "2020-06-07 15:15:56.332327 2300\n",
      "2020-06-07 15:16:07.542723 2400\n",
      "2020-06-07 15:16:18.361117 2500\n",
      "2020-06-07 15:16:29.450744 2600\n",
      "2020-06-07 15:16:39.895238 2700\n",
      "2020-06-07 15:16:50.901991 2800\n",
      "2020-06-07 15:17:01.500834 2900\n",
      "2020-06-07 15:17:12.221955 3000\n",
      "2020-06-07 15:17:22.874672 3100\n",
      "2020-06-07 15:17:33.307864 3200\n",
      "2020-06-07 15:17:44.076870 3300\n",
      "2020-06-07 15:17:55.182932 3400\n",
      "2020-06-07 15:18:05.548813 3500\n",
      "2020-06-07 15:18:15.946416 3600\n",
      "2020-06-07 15:18:26.473864 3700\n",
      "2020-06-07 15:18:37.081008 3800\n",
      "2020-06-07 15:18:47.675753 3900\n",
      "2020-06-07 15:18:57.996497 4000\n",
      "2020-06-07 15:19:08.963268 4100\n",
      "2020-06-07 15:19:19.327809 4200\n",
      "2020-06-07 15:19:29.785891 4300\n",
      "2020-06-07 15:19:40.642478 4400\n",
      "2020-06-07 15:19:51.282811 4500\n",
      "2020-06-07 15:20:01.835740 4600\n",
      "2020-06-07 15:20:12.876854 4700\n",
      "2020-06-07 15:20:23.903016 4800\n",
      "2020-06-07 15:20:35.163089 4900\n",
      "2020-06-07 15:20:46.125585 5000\n",
      "2020-06-07 15:20:57.064685 5100\n",
      "2020-06-07 15:21:08.117527 5200\n",
      "2020-06-07 15:21:18.847904 5300\n",
      "2020-06-07 15:21:29.507839 5400\n",
      "2020-06-07 15:21:40.757929 5500\n",
      "2020-06-07 15:21:51.342515 5600\n",
      "2020-06-07 15:22:02.144555 5700\n",
      "2020-06-07 15:22:12.794821 5800\n"
     ]
    }
   ],
   "source": [
    "# Read labels into pandas dataframe\n",
    "\n",
    "batch_input_filename = '/home/jupyter/batch-input.json'\n",
    "with open(, 'w') as fp:\n",
    "    for idx, blob_name in enumerate(blob_list[:]):\n",
    "\n",
    "        # Read blob from GCS\n",
    "        blob = photo_bucket.blob(blob_name)\n",
    "        blob_str = blob.download_as_string()\n",
    "        bytes_io = io.BytesIO(blob_str)\n",
    "        img = mpimg.imread(bytes_io, format='jpg')\n",
    "        img_red_downsample = img[::10,::10,0]\n",
    "\n",
    "        # Write to file\n",
    "        json_instances_dict = {'flatten_input': img_red_downsample.tolist()}\n",
    "        json.dump(json_instances_dict, fp)\n",
    "        fp.write('\\n')\n",
    "        \n",
    "        if idx % 100 == 0:\n",
    "            print(pd.Timestamp.now(), idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload batch input json file to GCS\n",
    "\n",
    "batch_input_blob = model_bucket.blob('batch-input/'+prefix+'.json')\n",
    "batch_input_blob.upload_from_filename(batch_input_filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Submit batch prediction job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_batch_job_body(project_name, input_paths, output_path,\n",
    "        model_name, region, data_format='JSON',\n",
    "        version_name=None, max_worker_count=None,\n",
    "        runtime_version=None):\n",
    "\n",
    "    project_id = 'projects/{}'.format(project_name)\n",
    "    model_id = '{}/models/{}'.format(project_id, model_name)\n",
    "    if version_name:\n",
    "        version_id = '{}/versions/{}'.format(model_id, version_name)\n",
    "\n",
    "    # Make a jobName of the format \"model_name_batch_predict_YYYYMMDD_HHMMSS\"\n",
    "    timestamp = time.strftime('%Y%m%d_%H%M%S', time.gmtime())\n",
    "\n",
    "    # Make sure the project name is formatted correctly to work as the basis\n",
    "    # of a valid job name.\n",
    "    clean_project_name = re.sub(r'\\W+', '_', project_name)\n",
    "\n",
    "    job_id = '{}_{}_{}'.format(clean_project_name, model_name,\n",
    "                           timestamp)\n",
    "\n",
    "    # Start building the request dictionary with required information.\n",
    "    body = {'jobId': job_id,\n",
    "            'predictionInput': {\n",
    "                'dataFormat': data_format,\n",
    "                'inputPaths': input_paths,\n",
    "                'outputPath': output_path,\n",
    "                'region': region}}\n",
    "\n",
    "    # Use the version if present, the model (its default version) if not.\n",
    "    if version_name:\n",
    "        body['predictionInput']['versionName'] = version_id\n",
    "    else:\n",
    "        body['predictionInput']['modelName'] = model_id\n",
    "\n",
    "    # Only include a maximum number of workers or a runtime version if specified.\n",
    "    # Otherwise let the service use its defaults.\n",
    "    if max_worker_count:\n",
    "        body['predictionInput']['maxWorkerCount'] = max_worker_count\n",
    "\n",
    "    if runtime_version:\n",
    "        body['predictionInput']['runtimeVersion'] = runtime_version\n",
    "\n",
    "    return body"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'jobId': 'optimum_treat_262616_logistic_regression_v1_20200607_165247',\n",
       " 'predictionInput': {'dataFormat': 'JSON',\n",
       "  'inputPaths': 'gs://cat-detection-models/batch-input/2020-06-01.json',\n",
       "  'outputPath': 'gs://cat-detection-models/batch-output/2020-06-01/',\n",
       "  'region': 'europe-west2',\n",
       "  'versionName': 'projects/optimum-treat-262616/models/logistic_regression_v1/versions/logistic_regression_v1',\n",
       "  'maxWorkerCount': 20}}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create batch job body\n",
    "\n",
    "batch_predict_body = make_batch_job_body(\n",
    "    project_name = project, \n",
    "    input_paths = f'gs://{model_bucket_name}/batch-input/{prefix}.json', \n",
    "    output_path = f'gs://{model_bucket_name}/batch-output/{prefix}/',\n",
    "    model_name = 'logistic_regression_v1', \n",
    "    region = 'europe-west2',\n",
    "    version_name='logistic_regression_v1', \n",
    "    max_worker_count=20)\n",
    "\n",
    "batch_predict_body"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Job requested.\n",
      "state : QUEUED\n"
     ]
    }
   ],
   "source": [
    "# Submit batch prediction job\n",
    "\n",
    "project_id = 'projects/{}'.format(project)\n",
    "\n",
    "ml = discovery.build('ml', 'v1')\n",
    "request = ml.projects().jobs().create(parent=project_id, body=batch_predict_body)\n",
    "\n",
    "try:\n",
    "    response = request.execute()\n",
    "\n",
    "    print('Job requested.')\n",
    "\n",
    "    # The state returned will almost always be QUEUED.\n",
    "    print('state : {}'.format(response['state']))\n",
    "\n",
    "except errors.HttpError as err:\n",
    "    # Something went wrong, print out some information.\n",
    "    print('There was an error getting the prediction results.' +\n",
    "          'Check the details:')\n",
    "    print(err._get_reason())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "name": "common-cpu.m46",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/base-cpu:m46"
  },
  "kernelspec": {
   "display_name": "cat-detection-4",
   "language": "python",
   "name": "cat-detection-4"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
